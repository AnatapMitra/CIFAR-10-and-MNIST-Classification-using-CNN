# -*- coding: utf-8 -*-
"""Classification from MNIST dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LUp-jk2F5S1idpNdas3f-8KGewRC7sn_
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt

# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Select only 5 classes (0-4)
selected_classes = [0, 1, 2, 3, 4]

# Filter the dataset to contain only the selected classes
train_filter = np.isin(y_train, selected_classes)
test_filter = np.isin(y_test, selected_classes)

x_train, y_train = x_train[train_filter], y_train[train_filter]
x_test, y_test = x_test[test_filter], y_test[test_filter]

# Normalize and preprocess the data
x_train = x_train / 255.0
x_test = x_test / 255.0

# Resize images to fit MobileNetV2 input size (128x128x3)
x_train_resized = np.array([cv2.resize(img, (128, 128)) for img in x_train])
x_test_resized = np.array([cv2.resize(img, (128, 128)) for img in x_test])

# Convert grayscale to RGB (MobileNetV2 expects 3-channel input)
x_train_resized = np.stack((x_train_resized,) * 3, axis=-1)
x_test_resized = np.stack((x_test_resized,) * 3, axis=-1)

# Convert labels to categorical (one-hot encoding)
y_train = to_categorical([selected_classes.index(label) for label in y_train], num_classes=5)
y_test = to_categorical([selected_classes.index(label) for label in y_test], num_classes=5)

# Split into train and validation sets
x_train, x_val, y_train, y_val = train_test_split(x_train_resized, y_train, test_size=0.2, random_state=42)

# Load the MobileNetV2 model with pre-trained ImageNet weights
base_model = MobileNetV2(input_shape=(128, 128, 3), include_top=False, weights='imagenet')

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Build the new model on top of MobileNetV2
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(5, activation='softmax')  # 5-class classification
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train,
                    validation_data=(x_val, y_val),
                    epochs=10,
                    batch_size=32)

# Evaluate on test set
test_loss, test_acc = model.evaluate(x_test_resized, y_test, verbose=0)
print(f"Test accuracy: {test_acc:.4f}")

# Plot training history
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Save the trained model
model.save("mnist_transfer_learning_model.h5")